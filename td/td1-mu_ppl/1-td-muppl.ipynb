{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install git+https://github.com/gbdrt/mu-ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mu_ppl import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An introduction to probabilistic programming with mu-PPL - MPRI 2.40\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilistic programs represent random variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice() -> int:\n",
    "    a = sample(RandInt(1, 6), name=\"a\")\n",
    "    b = sample(RandInt(1, 6), name=\"b\")\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run the experiment representing the random variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The law of the random variable can be computed by an inference algorithm. \n",
    "\n",
    "For instance the enumeration algorithm for discrete distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Enumeration():\n",
    "    dist: Categorical[int] = infer(dice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a sample of the distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the statistics of the distribution  and vizualize its mass function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s = dist.stats()\n",
    "print(\"mean: \",s[0], \"\\nstandard deviation: \", s[1])\n",
    "viz(dist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditioning can be hard: `assume(a!=b)` reject all samples that do not satisfy the property `a!=b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_dice() -> int:\n",
    "    a = sample(RandInt(1, 6), name=\"a\")\n",
    "    b = sample(RandInt(1, 6), name=\"b\")\n",
    "    assume (a != b)\n",
    "    return a + b\n",
    "\n",
    "with Enumeration():\n",
    "    dist: Categorical[int] = infer(hard_dice)\n",
    "    print(dist.stats())\n",
    "    viz(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def disk() -> Tuple[float, float]:\n",
    "    x = sample(Uniform(-1, 1))\n",
    "    y = sample(Uniform(-1, 1))\n",
    "    d2 = x**2 + y**2\n",
    "    assume (d2 < 1)\n",
    "    return (x, y)\n",
    "\n",
    "with RejectionSampling(num_samples=10000):\n",
    "    dist: Empirical = infer(disk)\n",
    "    x, y = zip(*dist.samples)\n",
    "    sns.scatterplot(x=x, y=y)\n",
    "    plt.axis(\"scaled\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditioning can be soft: `observe(Gaussian(d2, 0.1), o)` condition the law given observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position(o: float) -> Tuple[float, float]:\n",
    "    x = sample(Uniform(-1, 1))\n",
    "    y = sample(Uniform(-1, 1))\n",
    "    d2 = x**2 + y**2\n",
    "    observe(Gaussian(d2, 0.1), o)\n",
    "    return (x, y)\n",
    "\n",
    "with ImportanceSampling(num_particles=10000):\n",
    "    dist: Categorical = infer(position, 0.5)\n",
    "    w = dist.probs\n",
    "    x, y = list(zip(*dist.values))\n",
    "    plt.scatter(x, y, c=w**0.5, cmap='Reds', s=7)\n",
    "    plt.axis(\"scaled\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def success(s:int) -> int:\n",
    "    n = sample(RandInt(10, 20))\n",
    "    observe(Binomial(n, 0.5), s)\n",
    "    return n\n",
    "\n",
    "with ImportanceSampling(num_particles=10000):\n",
    "    dist: Categorical = infer(success, 10)\n",
    "    print(dist.stats())\n",
    "    viz(dist)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1** \n",
    "\n",
    "Describe the random variable that is modeled by this program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coin(obs: list[int]) -> float:\n",
    "    p = sample(Uniform(0, 1))\n",
    "    for o in obs:\n",
    "        observe(Bernoulli(p), o)\n",
    "    return p \n",
    "\n",
    "with ImportanceSampling(num_particles=10000):\n",
    "    dist: Categorical = infer(coin, [0, 0, 0, 0, 0, 0, 0, 0, 1, 1])\n",
    "    print(dist.stats())\n",
    "    viz(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Define a probabilistic program that models the number of tosses of a fair coin before getting a Tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "Use hard conditioning to define a probabilistic program that models a fair coin using two tosses of a bias coin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "Knuth and Yao proposed an algorithm that allow to simulate perfect 6 faces dice from a fair coin.\n",
    "\n",
    "From the initial state, we follow transitions according to the outcome of the toss of a fair coin until reaching a leave where the value is output.\n",
    "The 6 leaves are numbered from 11 to 16 and corresponds to the 6 faces.\n",
    "\n",
    "![Knuth Yao automata](./knuth-yao.jpg)\n",
    "\n",
    "D. Knuth et A. Yao.\n",
    "    *Algorithms and Complexity: New Directions and Recent Results, chapter The complexity of nonuniform random number generation*.\n",
    "  Academic Press, 1976."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the model and check with several inference methods that the result is a perfect dice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5**\n",
    "\n",
    "In 1886, Francis Galton measures the rate of regression in hereditary stature.\n",
    "\n",
    "He used a frequency table *Number of Adult Children of various Statures born of 205 Mid-Parents of various Statures*.\n",
    "\n",
    "He divided the data into subgroups according to the average height of the two parents. He computed the median of children stature against the median mid-parent stature and recognized a straight line.\n",
    "\n",
    "*Galton (1886) “Regression Towards Mediocrity in Hereditary Stature,” Journal\n",
    "of the Anthropological Institute of Great Britain and Ireland, 15, 246–263.*\n",
    "\n",
    "Use the following data to reproduce Galton result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "raw = pd.read_csv(\"galton.csv\")\n",
    "data = raw.loc[:,[\"parent\",\"child\"]]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_obs = data[\"parent\"]\n",
    "y_obs =  data[\"child\"]\n",
    "\n",
    "ax=plt.axes()\n",
    "ax.set_xlim(50, 80)\n",
    "ax.set_ylim(50,80)\n",
    "plt.scatter(x_obs, y_obs, color='red', zorder=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def model(data):\n",
    "    # modify the following model to fit the data\n",
    "    a = sample(Dirac(1), name=\"a\")\n",
    "    b = sample(Dirac(1), name=\"b\")\n",
    "    return (a, b)\n",
    "\n",
    "with ImportanceSampling(num_particles=1000):\n",
    "    dist: Categorical[Tuple[float,float]] = infer(model, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    x = np.linspace(55, 80, 2)\n",
    "    a, b = dist.sample()\n",
    "    plt.plot(x, a * x + b, color='blue', alpha=0.1, zorder=0)\n",
    "\n",
    "plt.scatter(x_obs, y_obs, color='red', zorder=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    x = np.linspace(0, 0.02, 2)\n",
    "    a, b = dist.sample()\n",
    "    plt.plot(x, a * x + b, color='blue', alpha=0.1, zorder=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TrueSkills™ is a skill-based ranking system developped by Microsoft for use with video game on XBox Live.[https://en.wikipedia.org/wiki/TrueSkill].\n",
    "\n",
    "The level of each player is represented by a gaussian distribution. We assume that for any player P, *skill_P~N(100,10)*.\n",
    "\n",
    "At each match, the skill of each player follows a gaussian distribution centered on their level and with a fixed variance. We observe the winner skill W is better than the skill of the loser L and update the random variables *skill_W* and *skill_L*.\n",
    "\n",
    "* *perf_W~ N(skill_W, 15)*\n",
    "* *perf_L~ N(skill_L, 15)*\n",
    "* *perf_W>perf_L*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement this model for 3 players and 3 matches: \n",
    "* A wins against B\n",
    "* B wins against C\n",
    "* A wins against C\n",
    "and check the results are what is wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In his book *Théorie analytique des probabilités, 1812*, Laplace compute the probability that the proportion of boys and girls registered in birth records is bigger in London than in Paris given historical data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace(f1: int, g1: int, f2: int, g2: int) -> float:\n",
    "    p = sample(Uniform(0, 1), name=\"p\")\n",
    "    q = sample(Uniform(0, 1), name=\"q\")\n",
    "    observe(Binomial(f1 + g1, p), g1)\n",
    "    observe(Binomial(f2 + g2, q), g2)\n",
    "    return q > p\n",
    "\n",
    "# Paris    1745 - 1784\n",
    "fp = 377555\n",
    "gp = 393386\n",
    "# Londres  1664 - 1758\n",
    "fl = 698958\n",
    "gl = 737629\n",
    "\n",
    "with ImportanceSampling(num_particles=100000):\n",
    "    dist: Categorical = infer(laplace, fp, gp, fl, gl)\n",
    "\n",
    "s = dist.stats()    \n",
    "print(\"q>p with probability \", s[0],\"\\nStandard deviation: \",s[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In his book *Théorie analytique des probabilités, 1812*, Laplace compute the probability that the proportion of boys and girls registered in birth records is bigger in London than in Paris given historical data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mu-ppl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
