{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebd6a5c9-c584-4c77-b362-a5f3c4b9a5b5",
   "metadata": {},
   "source": [
    "# Une courte introduction à Pyro\n",
    "\n",
    "https://pyro.ai/\n",
    "\n",
    "Pyro est un langage probabiliste construit sur Python et PyTorch.\n",
    "\n",
    "Comparé aux autres langages probabilistes, Pyro a mis l'accent sur l'inférence variationelle (SVI).\n",
    "PyTorch permet par ailleurs d'intégrer des réseaux de neurones complets dans les modèles probabilistes pour capturer des interactions complexes entre variables aléatoires.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a589434-61db-4132-af8e-caea2baf7891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "from pyro.distributions import Uniform, Bernoulli, Beta, Normal\n",
    "from pyro.infer import SVI, Trace_ELBO, MCMC, NUTS, Predictive\n",
    "from pyro.optim import Adam\n",
    "import pyro.infer.autoguide as autoguide\n",
    "\n",
    "import torch \n",
    "import torch.distributions.constraints as constraints\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3279b8-e0c1-4a53-925e-12fa70ca5376",
   "metadata": {},
   "source": [
    "## Exercice 1 : Inférence multiple pour une pièce biaisée.\n",
    "\n",
    "**Objectif.** L'objectif de cet exercice est de se familiariser avec Pyro et plusieurs techniques d'inférence sur un modèle bien connu.\n",
    "\n",
    "Les primitives Pyro sont les suivantes:\n",
    "\n",
    "- `x = pyro.sample('x', d)` implémente la construction `sample`\n",
    "- `pyro.sample('y', d, obs = y)` implémente la construction `observe`\n",
    "\n",
    "Remarque : En Pyro, les variables aléatoires (introduites par `sample`, observées ou non) doivent être associées à un nom unique le *sample site*. En général, on utilise le nom de la variable sauf en cas de conflit.\n",
    "\n",
    "### Modèle\n",
    "\n",
    "**Question 1** Implémenter le modèle de la pièce biaisé en Pyro. On utilisera une boucle Python pour itérer sur le tableau de données (attention au nommage des variables aléatoires)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827ccacf-ac97-4167-9300-84378d2a655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5415d3-fca2-4233-8218-dcaefa622af1",
   "metadata": {},
   "source": [
    "### SVI\n",
    "\n",
    "Il faut maintenant définir un guide (une famille variationnelle) pour SVI.\n",
    "Le guide doit échantillonner les mêmes variables que le modèle (ici `z`) sur le même domaine de définition (ici $[0, 1]$).\n",
    "Le guide doit également avoir la même signature que le modèle (entrées et sorties).\n",
    "\n",
    "Les paramètres du guide sont introduits à l'aide de la primitive `pyro.param('p', v0, constraint=c)`.\n",
    "Chaque paramètre est associé à un nom unique et une valeur initiale.\n",
    "Le paramètre optionnel `constraint` permet de spécifier des contraintes (cf `torch.distributions.constraints`), par exemple `constraints.positive`.\n",
    "\n",
    "\n",
    "**Question 2** Implémenter un guide pour le modèle précédent.\n",
    "\n",
    "_Note_: On pourra par exemple chercher une distribution $\\mathit{Beta}(\\alpha, \\beta)$ où $\\alpha \\geq 0$ et $\\beta \\geq 0$ sont les paramètres de la famille variationnelle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afb99a1-7f4c-40a5-aeec-556a87c0aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guide(x):\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec76a6c-3665-4e63-b204-45ead4740c63",
   "metadata": {},
   "source": [
    "Il ne reste plus qu'à lancer l'inférence.\n",
    "Pyro utilise les _optimizers_ de PyTorch comme `Adam` pour trouver la valeur des paramètres du guide.\n",
    "\n",
    "_Note_: L'ajout de noms uniques permet à Pyro de croiser les variables aléatoires du modèle et du guide pour résoudre le problème d'optimisation (toutes les variables sont ajoutées à un environnement global, on peut donc y acceder en dehors des fonctions `model` et `guide`).\n",
    "Malheureusement, on perd ainsi la portée des variables et c'est au programmeur d'éviter les conflits de noms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c756d4-e5e6-445e-9bbf-1beb9f5e2515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, guide, data, n_steps = 5000):\n",
    "    # optimizer\n",
    "    optimizer = Adam({\"lr\": 0.0005, \"betas\": (0.90, 0.999)})\n",
    "    # create svi object from model and guide to run inference\n",
    "    svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "    # do gradient steps\n",
    "    for step in tqdm(range(n_steps), ncols=80):\n",
    "        svi.step(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bae0c28-6bc9-4563-adf0-d79a4817c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
    "\n",
    "train(model, guide, data, n_steps= 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60536c34-6815-43ed-9486-282f0292264f",
   "metadata": {},
   "source": [
    "Une fois l'inférence terminée on peut récuperer la valeur finale des paramètres et calculer les moments de la distibution $\\mathit{Beta}$ obtenue.\n",
    "\n",
    "**Question 3.** Calculer ces moments (cf $\\mathit{Beta}$ distribution) à partir des valeurs de $\\alpha$ et $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7e6f86-0a6b-4a99-a102-d664365d5fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = pyro.param(\"alpha\").item()\n",
    "beta = pyro.param(\"beta\").item()\n",
    "\n",
    "mean = # TODO\n",
    "std = # TODO\n",
    "\n",
    "print(f\"Mean: {mean}, Std: {std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1831d66c-0be6-41df-a9f0-ee797b9fad1c",
   "metadata": {},
   "source": [
    "### Autoguide\n",
    "\n",
    "En pratique programmer un guide peut être difficile.\n",
    "Pyro offre un zoo d'autoguides qui sont synthétisés à partir du modèle.\n",
    "\n",
    "Par exemple, le plus simple `AutoDelta` cherche une distribution de Dirac (un maximum à posteriori)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c2d622-2763-4e15-b362-c17120bc3a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "guide = autoguide.AutoDelta(model)\n",
    "train(model, guide, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d90477f-802f-48fd-89ce-3ab9a9285799",
   "metadata": {},
   "source": [
    "On peut ensuite afficher l'ensemble des paramètres calculés par Pyro.\n",
    "Le paramètre `AutoDelta.z` vient du guide synthétisé par `AutoDelta`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d721443-7746-4c4f-9ec5-81d84727a3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in pyro.get_param_store().items():\n",
    "    print(name, pyro.param(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b3d530-450c-49a0-813f-577f067ab846",
   "metadata": {},
   "source": [
    "_Note_: Le `param_store` contient tous les paramètres calculés depuis le début de la session Python.\n",
    "Il peut être réinitialisé avec la commande `pyro.clear_param_store()`.\n",
    "\n",
    "_Note_: Attention l'inférence est exécutée dans un espace non-contraint ($\\mathbb{R}^n$).\n",
    "Les resultats qui apparaissent dans le `param_store` sont donc transformés (essayer`AutoNormal` par exemple).\n",
    "On peut utiliser les fonctions Pyro `guide.median()` ou `guide.quantiles([0.25, 0.5, 0.75])` pour obtenir des résultats directement interpretables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54113c29-1173-4e75-8aa1-4af92300f9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Median: {guide.median()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d73570-d689-4c78-8066-8bba6d06b6b6",
   "metadata": {},
   "source": [
    "On peut également appeler directement le guide après l'inférence pour générer des échantillons (par défaut un objet contenant toutes les variables latentes du guide).\n",
    "Pour `AutoDelta`, on renvoie toujours la même valeur (Dirac), mais d'autres guides génèrent des échantillons différents à chaque appel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba56cfa2-9204-4f7c-9676-21a0ec8eda02",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(guide(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c553af4c-48e6-47c8-9608-b7f59feea41d",
   "metadata": {},
   "source": [
    "**Question 4.** Essayer d'autres autoguides pour le même modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8cf5c7-f301-4c64-987d-519b4454a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66194786-5dcb-4b39-ba5b-32c21a875e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db46a761-3dec-4312-bbc8-60ebc2335459",
   "metadata": {},
   "source": [
    "### MCMC\n",
    "\n",
    "Pyro permet de tester plusieurs méthodes d'inférence sur le même modèle. \n",
    "On peut par exemple essayer NUTS, un noyau optimisé de Hamiltonian Monte Carlo pour MCMC (qui est aussi la méthode d'inférence par defaut de Stan)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc9c774-2065-457b-98ac-8dfb8d848fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = NUTS(model, jit_compile=True, ignore_jit_warnings=True)\n",
    "posterior = MCMC(kernel, num_samples=1000, warmup_steps=100)\n",
    "posterior.run(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aefe36-7602-4aa2-bce7-54f8e165263e",
   "metadata": {},
   "source": [
    "Pour récupérer les échantillons de la distribution à posteriori, on peut appeler la methode `get_samples` sur `posterior`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e44836-900f-4e55-9e91-e0d1eaa3b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior.get_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2e6484-b4d5-45ff-ae78-5b0471384335",
   "metadata": {},
   "source": [
    "**Question 5.** En déduire les moments de la distribution obtenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19b8eb0-ee0c-45cc-a7ae-f3937c89fda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4468360c-20ba-4feb-ae8d-b88129b9af80",
   "metadata": {},
   "source": [
    "On peut également utiliser la méthode `posterior.summary()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0916020-dc4b-4276-bcd2-8c7688d8f408",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3594496-b9f4-4c0c-b2b7-0f9c50ba64cf",
   "metadata": {},
   "source": [
    "_Remarque_ : Il existe également une implémentation de Pyro, NumPyro, qui utilise JAX à la place de PyTorch https://num.pyro.ai/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83244274-7a36-42fe-ba62-478f10aa0221",
   "metadata": {},
   "source": [
    "## Exercice 2 : Titanic\n",
    "\n",
    "Adapté de https://www.kaggle.com/c/titanic/\n",
    "\n",
    "**Objectif.** L'objectif de cet exercice est de prédire si un passager va survivre au naufrage du Titanic en fonction de données telles que son âge, son sexe, ou le prix de son billet.\n",
    "\n",
    "Les données sont les suivantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7755422-b74d-4992-afd2-da693b1b089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw = pd.read_csv(\"titanic.csv\")\n",
    "df = raw.loc[:,[\"Survived\"]]\n",
    "df[\"Sex\"] = raw[\"Sex\"].apply(lambda s: 0 if s == \"male\" else 1)\n",
    "df[\"Age\"] = raw[\"Age\"].fillna(raw[\"Age\"].median())\n",
    "df[\"Fare\"] = raw[\"Fare\"].fillna(raw[\"Fare\"].median())\n",
    "\n",
    "# Dictionnary contaning all the data as torch tensors\n",
    "data = { \n",
    "    k : torch.tensor(df[k]).double()\n",
    "    for k in df.columns    \n",
    "}\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9610ff-0fb6-4bea-8c95-34c92121afab",
   "metadata": {},
   "source": [
    "**Question 1.** Proposer un modèle de régression logistique pour prédire la survie d'un passager.\n",
    "\n",
    "_Note_ Une régression logistique est similaire à une régression linéaire pour les problèmes de classification.\n",
    "Le modèle général est le suivant.\n",
    "\n",
    "\\begin{align*}\n",
    "a &\\sim \\mathcal{N}(0, 1)\\\\\n",
    "b &\\sim \\mathcal{N}(0, 1)\\\\\n",
    "l &= a x + b\\\\\n",
    "z &= \\frac{1}{1 + e^{-l}}\\\\\n",
    "y &\\sim \\mathit{Bernoulli}(z)\n",
    "\\end{align*}\n",
    "\n",
    "Ici les données $x$ se décomposent en $x_{\\mathrm{age}}$, $x_{\\mathrm{sex}}$ et $x_{\\mathrm{fare}}$.\n",
    "On cherche donc une régression linéaire de la forme \n",
    "\n",
    "$$\n",
    "l = a_{\\mathrm{age}} * x_{\\mathrm{age}} + a_{\\mathrm{sex}} * x_{\\mathrm{sex}} + a_{\\mathrm{fare}} * x_{\\mathrm{fare}} + b\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeb2cee-7367-4bf6-bb68-3953ac93f4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data):\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bce9c5-cc9d-4deb-a60c-af76a5dcf655",
   "metadata": {},
   "source": [
    "**Question 2.** Executer l'inférence de votre choix sur votre modèle avec les données `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbeb7b0-2c95-4939-92c4-3ba0ad315997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c493f3-2d5b-4ac3-9cf4-302d4e693fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c621cca-fe58-41c5-93db-d19c5b36afd5",
   "metadata": {},
   "source": [
    "**Question 3.** Exploiter les résultats obtenus pour faire des prédictions sur le même jeux de données.\n",
    "\n",
    "_Note_: On pourra utiliser l'outil `Predictive` de Pyro. \n",
    "Étant donné un modèle `model` et un ensemble d'échantillons de la distribution a posteriori `samples`, \n",
    "`Predictive(model, samples).forward(data)` génère de nouvelles valeurs pour toutes les observations (si elles sont à `None` dans `data`).\n",
    "On peut ensuite moyenner ces échantillons pour obtenir une prédiction.\n",
    "Dans notre cas, on pourra utiliser `Predictive(model, samples).forward({**data, \"Survived\":None})` pour prédire la survie d'un passager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9861e19f-a50a-4a3b-ab84-33a36299ee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_predictive = Predictive(model, samples).forward({**data, \"Survived\":None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1db3215-879d-4de1-bf40-ce89404ba6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Prediction\"] = # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a9aeaa-b2e8-4000-8eb3-bb4fa25b25ca",
   "metadata": {},
   "source": [
    "**Question 4.** Quelle est la précision de votre modèle sur ce jeux de données ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0a8d93-6726-4891-8f9c-d78f6c1d27f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202dab66-c6b8-4d13-ab83-f8839bec6be2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
